#!/bin/bash
set -e

echo "ğŸš€ Step 1: å°†æ€»è°±æ–‡æ–‡æœ¬æŒ‰é€—å·åˆ†è¯ä¸ºtokenåºåˆ—..."

python3 scripts/text_to_tokenized_list.py \
  --text_file data/raw/full_text.txt \
  --output_path data/score_tokenized_raw.pt

echo "âœ… å®Œæˆé€—å·åˆ†è¯å¹¶ä¿å­˜è‡³ data/score_tokenized_raw.pt"

# --------------------------------------

echo "ğŸš€ Step 2: å°†å°ç‰‡æ®µtokenså‡åˆ†ç»„åˆä¸º5é¦–å®Œæ•´æ›²å­..."

python3 scripts/prepare_score_tokenized.py \
  --input_path data/score_tokenized_raw.pt \
  --output_path data/score_tokenized.pt \
  --n_pieces 5

echo "âœ… å®Œæˆæ›²å­åˆ†ç»„ï¼Œç”Ÿæˆæ ‡å‡†è°±æ–‡tokens data/score_tokenized.pt"

echo "ğŸ¯ å®Œæˆ prepare_score_full æµç¨‹ï¼"
