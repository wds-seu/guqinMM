#!/bin/bash

# ========== è®¾ç½®è¶…å‚æ•° ==========
DATA_DIR="./data/finetune_data"       # ä½ çš„è°±æ–‡+éŸ³é¢‘5é¦–æ•°æ®
CHECKPOINT_DIR="./checkpoints_finetune"
PRETRAINED_MODEL="./checkpoints/pretrain_latest.pt"   # ä½ çš„é¢„è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
RESULT_DIR="./results"
EPOCHS=10
BATCH_SIZE=4
LEARNING_RATE=1e-4
MAX_LENGTH=1024

# è®¾å¤‡è®¾ç½®ï¼ˆä½¿ç”¨å…¨éƒ¨GPUï¼‰
export CUDA_VISIBLE_DEVICES=0,1

echo "ğŸš€ Step 1: å¼€å§‹å¾®è°ƒ Finetune"
python train_finetune.py \
    --data_dir $DATA_DIR \
    --pretrained_model $PRETRAINED_MODEL \
    --save_dir $CHECKPOINT_DIR \
    --epochs $EPOCHS \
    --batch_size $BATCH_SIZE \
    --learning_rate $LEARNING_RATE \
    --max_length $MAX_LENGTH

# å–æœ€æ–°finetuneåçš„checkpoint
LATEST_CKPT=$(ls -t $CHECKPOINT_DIR/*.pt | head -n 1)

echo "âœ… Finetuneå®Œæˆï¼Œæœ€æ–°æ¨¡å‹ï¼š$LATEST_CKPT"

# ========== æ¨ç†å‚æ•°è®¾ç½® ==========
METHOD="sampling"    # å¯é€‰ sampling / beam
TOP_K=20
TOP_P=0.9
TEMPERATURE=1.0
BEAM_WIDTH=5

SCORE_TOKENS_PATH="./data/inference/score_tokens.pt"  # æ¨ç†è¾“å…¥
STYLE_LABEL=0  # æµæ´¾ç±»åˆ«ï¼Œæ¯”å¦‚ exam = 0

mkdir -p $RESULT_DIR

echo "ğŸš€ Step 2: å¼€å§‹æ¨ç† Inference ($METHOD)"
python inference_generate_main.py \
    --model_ckpt $LATEST_CKPT \
    --score_tokens_path $SCORE_TOKENS_PATH \
    --style_label $STYLE_LABEL \
    --method $METHOD \
    --max_length $MAX_LENGTH \
    --top_k $TOP_K \
    --top_p $TOP_P \
    --temperature $TEMPERATURE \
    --beam_width $BEAM_WIDTH \
    --save_dir $RESULT_DIR

echo "ğŸµ ç”Ÿæˆå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ $RESULT_DIR ä¸‹ï¼"

